{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item1 = [\n",
    "    \"Accruals\",\n",
    "    \"NOA\",\n",
    "    \"PS\",\n",
    "    \"ZScore\",\n",
    "    \"CompositeDebtIssuance\",\n",
    "    \"ShareIss1Y\",\n",
    "    \"XFIN\",\n",
    "    \"ShareIss5Y\",\n",
    "    \"FirmAge\",\n",
    "    \"AssetGrowth\",\n",
    "    \"ChNWC\",\n",
    "    \"BookLeverage\",\n",
    "    \"Illiquidity\",\n",
    "    \"VolSD\",\n",
    "    \"LRreversal\",\n",
    "    \"IntMom\",\n",
    "    \"Mom12m\",\n",
    "    \"Mom6m\",\n",
    "    \"High52\",\n",
    "    \"MomSeasonShort\",\n",
    "    \"MomSeason11YrPlus\",\n",
    "    \"MomSeason06YrPlus\",\n",
    "    \"MomSeason\",\n",
    "    \"MomSeason16YrPlus\",\n",
    "    \"Herf\",\n",
    "    \"InvGrowth\",\n",
    "    \"CBOperProf\",\n",
    "    \"roaq\",\n",
    "    \"RoE\",\n",
    "    \"PM\",\n",
    "    \"OperProf\",\n",
    "    \"GP\",\n",
    "    \"pchsaleinv\",\n",
    "    \"Beta\",\n",
    "    \"ChAssetTurnover\",\n",
    "    \"STreversal\",\n",
    "    \"Size\",\n",
    "    \"cfp\",\n",
    "    \"SP\",\n",
    "    \"BM\",\n",
    "    \"EP\",\n",
    "    \"IdioVol3F\",\n",
    "    \"MaxRet\",\n",
    "    \"DolVol\"\n",
    "]\n",
    "   \n",
    "\n",
    "item2 = [\n",
    "    \"Accruals\",\n",
    "    \"OScore\",\n",
    "    \"NOA\",\n",
    "    \"ChNAnalyst\",\n",
    "    \"ZScore\",\n",
    "    \"FailureProbability\",\n",
    "    \"EarningsSurprise\",\n",
    "    \"CompEquIss\",\n",
    "    \"FirmAge\",\n",
    "    \"ChNWC\",\n",
    "    \"MomVol\",\n",
    "    \"CustomerMomentum\",\n",
    "    \"BPEBM\",\n",
    "    \"Illiquidity\",\n",
    "    \"std_turn\",\n",
    "    \"VolSD\",\n",
    "    \"BetaLiquidityPS\",\n",
    "    \"BetaBDLeverage\",\n",
    "    \"DivSeason\",\n",
    "    \"DivOmit\",\n",
    "    \"DivInit\",\n",
    "    \"ResidualMomentum\",\n",
    "    \"Mom6mJunk\",\n",
    "    \"CPVolSpread\",\n",
    "    \"RIVolSpread\",\n",
    "    \"MomSeasonShort\",\n",
    "    \"MomSeason11YrPlus\",\n",
    "    \"MomSeason06YrPlus\",\n",
    "    \"MomOffSeason\",\n",
    "    \"MomSeason\",\n",
    "    \"MomOffSeason06YrPlus\",\n",
    "    \"MomSeason16YrPlus\",\n",
    "    \"MomOffSeason16YrPlus\",\n",
    "    \"RDAbility\",\n",
    "    \"MomOffSeason11YrPlus\",\n",
    "    \"roaq\",\n",
    "    \"RoE\",\n",
    "    \"PM\",\n",
    "    \"Coskewness\",\n",
    "    \"ChAssetTurnover\",\n",
    "    \"ChPM\",\n",
    "    \"ShareVol\",\n",
    "    \"BM\",\n",
    "    \"EP\",\n",
    "    \"Frontier\",\n",
    "    \"CF\",\n",
    "    \"EBM\",\n",
    "    \"AnalystValue\",\n",
    "    \"DivYield\",\n",
    "    \"VolMkt\"\n",
    "]\n",
    "csv_list = item1 + item2\n",
    "# delete the duplicate items\n",
    "csv_list = list(set(csv_list))\n",
    "len(csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cd = 'CtsPredictorQuintileVW'\n",
    "# 初始化一个空的 DataFrame\n",
    "df = pd.DataFrame()\n",
    "# 初始化一个列表来记录不存在的文件\n",
    "missing_files = []\n",
    "\n",
    "# 合并所有 CSV 文件到一个 DataFrame\n",
    "for file in csv_list:\n",
    "    file_path = f'{cd}/{file}_ret.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        temp_df = pd.read_csv(file_path)\n",
    "        factor_name = file  # 直接使用文件名作为因子名称\n",
    "        temp_df['predictor'] = factor_name  # 添加一个新列来标识文件来源\n",
    "        df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    else:\n",
    "        missing_files.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date    port01    port02    port03    port04    port05    portLS  \\\n",
      "399086 1952-07-01  0.124831  0.336154  0.839240  0.637685  0.656345  0.531514   \n",
      "399087 1952-07-02 -0.246625 -0.244496 -0.049348 -0.189462 -0.104565  0.142060   \n",
      "399088 1952-07-03  0.023978  0.084967 -0.142413 -0.223899 -0.035177 -0.059155   \n",
      "399089 1952-07-07 -0.171018 -0.076185 -0.263179 -0.661418 -0.503844 -0.332827   \n",
      "399090 1952-07-08 -0.209479  0.235904 -0.025679  0.218441  0.140033  0.349512   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "128115 2023-12-22  1.857859  0.723824  0.498934  0.233261  0.428393 -1.429466   \n",
      "128116 2023-12-26  3.266919  0.875071  1.303056  0.540725  0.561904 -2.705015   \n",
      "128117 2023-12-27  2.341186  0.200744  0.285204  0.159429  0.059149 -2.282037   \n",
      "128118 2023-12-28 -1.669881 -0.263774 -0.543158 -0.266308 -0.110725  1.559157   \n",
      "128119 2023-12-29 -2.447862 -1.850345 -0.757195 -0.082058 -0.068660  2.379202   \n",
      "\n",
      "       predictor  \n",
      "399086  Accruals  \n",
      "399087  Accruals  \n",
      "399088  Accruals  \n",
      "399089  Accruals  \n",
      "399090  Accruals  \n",
      "...          ...  \n",
      "128115  std_turn  \n",
      "128116  std_turn  \n",
      "128117  std_turn  \n",
      "128118  std_turn  \n",
      "128119  std_turn  \n",
      "\n",
      "[1237148 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.sort_values(by=['predictor', 'date'], inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "# get the unique factors\n",
    "unique_factors = df['predictor'].nunique()\n",
    "print(unique_factors)\n",
    "\n",
    "with open('factors.txt', 'w') as f:\n",
    "\tf.write(str(unique_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following files were not found:\n",
      "CtsPredictorQuintileVW/BetaBDLeverage_ret.csv\n",
      "CtsPredictorQuintileVW/pchsaleinv_ret.csv\n",
      "CtsPredictorQuintileVW/DivSeason_ret.csv\n",
      "CtsPredictorQuintileVW/DivOmit_ret.csv\n",
      "CtsPredictorQuintileVW/PM_ret.csv\n",
      "CtsPredictorQuintileVW/ChPM_ret.csv\n",
      "CtsPredictorQuintileVW/ZScore_ret.csv\n",
      "CtsPredictorQuintileVW/ShareVol_ret.csv\n",
      "CtsPredictorQuintileVW/DivYield_ret.csv\n",
      "CtsPredictorQuintileVW/OScore_ret.csv\n",
      "CtsPredictorQuintileVW/MomVol_ret.csv\n",
      "CtsPredictorQuintileVW/DivInit_ret.csv\n",
      "CtsPredictorQuintileVW/ChNAnalyst_ret.csv\n",
      "CtsPredictorQuintileVW/FailureProbability_ret.csv\n"
     ]
    }
   ],
   "source": [
    "# get the missed files\n",
    "if missing_files:\n",
    "    print(\"The following files were not found:\")\n",
    "    for missing_file in missing_files:\n",
    "        print(missing_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the merged DataFrame to a csv file\n",
    "df.to_csv(f'data/merged_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
